{"nbformat_minor": 2, "cells": [{"source": "## Configuration\n\nAdd Delta Lake Package and Configure spark.sql.extensions and spark.sql.catalog.spark_catalog", "cell_type": "markdown", "metadata": {"editable": true, "deletable": true}}, {"execution_count": null, "cell_type": "code", "source": "%%configure -f\n{ \"conf\": {\"spark.jars.packages\": \"io.delta:delta-core_2.12:1.0.1,net.andreinc:mockneat:0.4.8\",\n           \"spark.sql.extensions\":\"io.delta.sql.DeltaSparkSessionExtension\",\n           \"spark.sql.catalog.spark_catalog\":\"org.apache.spark.sql.delta.catalog.DeltaCatalog\"\n          }\n}", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 18.546875, "end_time": 1669694274683.965}}, "editable": true, "collapsed": false, "deletable": true}}, {"source": "## Generate MockData using MockNeat\n- Use Mockneat for Random Data Generation\n- Generate Customer Data using Mocknet Library\n- Configuration:\n   - numberOfRecords - number of records to generate", "cell_type": "markdown", "metadata": {"editable": true, "deletable": true}}, {"execution_count": null, "cell_type": "code", "source": "import net.andreinc.mockneat.MockNeat\nimport net.andreinc.mockneat.abstraction.MockUnit\nimport net.andreinc.mockneat.types.enums.RandomType\nimport java.time.LocalDate\nimport scala.reflect.ClassTag\n\nval mockNeat = MockNeat.threadLocal()\n\n/**\n* Customer Business Model\n**/\ncase class Customer(var customerId: Int, var customerName: String, var firstName: String,\n                    var lastName: String, var userName: String, var registrationDate: String)\n//configure base on your need\n// this program will run on driver side limit by driver memory\nval DateStart = LocalDate.of(2014, 1, 1)\nval DateEnd = LocalDate.of(2016, 1, 1)\nval numberOfRecords = 10\n\nval customerData = (1 to numberOfRecords).map(i=>{\n    Customer(i,\n             mockNeat.names().full().get(),\n             mockNeat.names().first().get(),\n             mockNeat.names().last().get(),\n             mockNeat.users().get(),\n             mockNeat.localDates.between(DateStart, DateEnd).mapToString().get())\n})", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 2282.529052734375, "end_time": 1669695646413.114}}, "editable": true, "collapsed": false, "deletable": true}}, {"source": "## Change the Path where you want to save your data\n- Configuration\n    - adsl2Path - path where we would like to save delta lake data, It can be a full path or relative path. [More details](https://learn.microsoft.com/en-us/azure/hdinsight/overview-azure-storage#hdinsight-storage-architecture)", "cell_type": "markdown", "metadata": {"cell_status": {"execute_time": {"duration": 247.60693359375, "end_time": 1669679217925.857}}, "editable": true, "deletable": true}}, {"execution_count": null, "cell_type": "code", "source": "// define Delta Lake Path\nval adsl2Path = \"/tmp/customerdata2\"\n\n//create data frame\nval df = sc.parallelize(customerData).toDF\ndf.write.mode(\"overwrite\").format(\"delta\").save(adsl2Path)\n// print schema of the dataframe\ndf.printSchema", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 23455.97900390625, "end_time": 1669695291570.074}}, "editable": true, "collapsed": false, "deletable": true}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "Spark", "name": "sparkkernel", "language": ""}, "language_info": {"mimetype": "text/x-scala", "pygments_lexer": "scala", "name": "scala", "codemirror_mode": "text/x-scala"}, "celltoolbar": "Raw Cell Format"}}

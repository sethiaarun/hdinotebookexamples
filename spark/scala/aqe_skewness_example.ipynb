{"nbformat_minor": 2, "cells": [{"source": "# Data Setup\nThis example uses two sets of data, items and sales transactions. This data Setup is done using Spark SQL and UDF functions.\nThe total number of items and sales transactions are configurable.\n# Analysis\nTotal sales (sold qty * unit price) are grouped by transaction date. \n# Execution\nExecute this notebook without AQE enabled and with AQE Enabled to compare execution time.", "cell_type": "markdown", "metadata": {"editable": true, "deletable": true}}, {"execution_count": null, "cell_type": "code", "source": "%%configure -f\n{ \"conf\": {\"spark.sql.adaptive.enabled\":\"false\",\n           \"spark.executor.instances\":\"5\"\n          }\n}", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 30.3759765625, "end_time": 1685544353955.032}}, "editable": true, "collapsed": false, "deletable": true}}, {"source": "## Data Setup", "cell_type": "markdown", "metadata": {"editable": true, "deletable": true}}, {"execution_count": null, "cell_type": "code", "source": "// first disable AQE and SkewJoin\n//sql(\"SET spark.sql.adaptive.enabled=true\")\n//sql(\"SET spark.sql.adaptive.skewJoin.enabled=true\")\n\nval noOfItems = 2000000\nval noOfSaleTx = 1000000000\n//UDF to generate random string with given length\nval randomString =udf((length: Int)=> scala.util.Random.alphanumeric.take(length).mkString)\nspark.udf.register(\"randomString\",randomString)\n//UDF to generate random float\nval randomFloat=udf(()=>scala.util.Random.nextFloat())\nspark.udf.register(\"randomFloat\",randomFloat)\n//UDF to generate random integer quantity\nval randomQty=udf((max:Int)=>scala.util.Random.nextInt(10))\nspark.udf.register(\"randomQty\",randomQty)\n\n\n/* list of items schema \nroot\n |-- name: string (nullable = true)\n |-- unit_price: float (nullable = true)\n |-- item_id: long (nullable = false)\n*/\nval itemDF = sql(s\"\"\"SELECT randomString(10) as name,\n                        round(randomFloat()*10,2) as unit_price,\n                        id as item_id FROM range($noOfItems)\"\"\")\n\nitemDF.write.format(\"parquet\").mode(\"overwrite\").saveAsTable(\"item\")\n\n/* list of sales transactions - skewness for item#18\n root\n |-- item_id: integer (nullable = true)\n |-- soldQty: integer (nullable = false)\n |-- tx_id: long (nullable = false)\n |-- tx_date: date (nullable = true)\n*/\nval salesDF = sql(s\"\"\"SELECT CASE WHEN randomFloat() < 0.9 THEN 18 ELSE CAST(randomFloat() * $noOfItems AS INT) END AS item_id,\n                      randomQty(10) as soldQty,\n                      id as tx_id,\n                      DATE_ADD(current_date(), - CAST(randomFloat() * 90 AS INT)) AS tx_date FROM range($noOfSaleTx)\"\"\")\n\nsalesDF.write.format(\"parquet\").mode(\"overwrite\").saveAsTable(\"sale\")", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 206269.0859375, "end_time": 1685546005176.514}}, "editable": true, "collapsed": false, "deletable": true}}, {"source": "## Analysis", "cell_type": "markdown", "metadata": {"editable": true, "deletable": true}}, {"execution_count": null, "cell_type": "code", "source": "%%sql\nSELECT tx_date, sum(soldQty * unit_price) AS total_sales\nFROM sale\nJOIN item ON item.item_id = sale.item_id\nGROUP BY tx_date", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 57555.5810546875, "end_time": 1685546249625.137}}, "editable": true, "collapsed": false, "deletable": true}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "Spark", "name": "sparkkernel", "language": ""}, "language_info": {"mimetype": "text/x-scala", "pygments_lexer": "scala", "name": "scala", "codemirror_mode": "text/x-scala"}}}
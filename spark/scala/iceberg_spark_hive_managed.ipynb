{"nbformat_minor": 5, "cells": [{"execution_count": null, "cell_type": "code", "source": "%%configure -f\n{ \"conf\": {\"spark.jars.packages\": \"org.apache.iceberg:iceberg-spark-runtime-3.1_2.12:0.13.1\",\n           \"spark.sql.extensions\":\"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\",\n           \"spark.sql.catalog.spark_catalog\":\"org.apache.iceberg.spark.SparkSessionCatalog\",\n           \"spark.sql.catalog.spark_catalog.type\":\"hive\",\n           \"spark.sql.catalog.dev\":\"org.apache.iceberg.spark.SparkCatalog\",\n           \"spark.sql.catalog.dev.type\":\"hive\",\n           \"spark.sql.catalog.dev.warehouse\":\"/icebergwarehouse\"\n          }\n}", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 761.10791015625, "end_time": 1675791398898.253}}, "editable": true, "collapsed": false, "deletable": true}}, {"execution_count": null, "cell_type": "code", "source": "import org.apache.spark.sql.SaveMode\nimport org.apache.spark.sql.functions._\n\n// Create a DataFrame.\nval data = Seq(\n(\"100\", \"2015-01-01\", \"2015-01-01T13:51:39.340396Z\"),\n(\"101\", \"2015-01-01\", \"2015-01-01T12:14:58.597216Z\"),\n(\"102\", \"2015-01-01\", \"2015-01-01T13:51:40.417052Z\"),\n(\"103\", \"2015-01-01\", \"2015-01-01T13:51:40.519832Z\")\n).toDF(\"id\", \"creation_date\", \"last_update_time\")\n\n// Write a DataFrame as a Iceberg dataset to the Amazon S3 location.\nspark.sql(\"\"\"CREATE TABLE IF NOT EXISTS iceberg_table2 (id string,\ncreation_date string,\nlast_update_time string) USING iceberg\"\"\")", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 2276.8779296875, "end_time": 1675793325482.365}}, "editable": true, "collapsed": false, "deletable": true}}, {"execution_count": null, "cell_type": "code", "source": "data.writeTo(\"iceberg_table2\").append()", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 2282.635986328125, "end_time": 1675793334030.012}}, "editable": true, "collapsed": false, "deletable": true}}, {"execution_count": null, "cell_type": "code", "source": "val df = spark.read.format(\"iceberg\").load(\"iceberg_table2\")\ndf.show()", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 2276.2060546875, "end_time": 1675793469862.951}}, "editable": true, "collapsed": false, "deletable": true}}, {"execution_count": null, "cell_type": "code", "source": "", "outputs": [], "metadata": {"collapsed": true, "editable": true, "deletable": true}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "Spark", "name": "sparkkernel", "language": ""}, "language_info": {"mimetype": "text/x-scala", "pygments_lexer": "scala", "name": "scala", "codemirror_mode": "text/x-scala"}}}
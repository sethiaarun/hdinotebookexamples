{"nbformat_minor": 2, "cells": [{"source": "# Data Setup\nThis example uses two sets of data, customer and sales transactions. This data Setup is done using Spark SQL and UDF functions.\nThe total number of customers (small number of customers; those are used for sales data in cycle/repetition) and sales transactions are configurable.\n\n# Analysis\nAggregate sales value by date.\n\n# Execution\nExecute this notebook without AQE enabled and with AQE Enabled to compare execution time.", "cell_type": "markdown", "metadata": {"editable": true, "deletable": true}}, {"execution_count": null, "cell_type": "code", "source": "%%configure -f\n{ \"conf\": {\"spark.sql.adaptive.enabled\":\"false\",\n           \"spark.executor.instances\":\"5\"\n          }\n}", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 27.200927734375, "end_time": 1685560480751.73}}, "editable": true, "collapsed": false, "deletable": true}}, {"execution_count": null, "cell_type": "code", "source": "sql(\"DROP table IF EXISTS customer\")\nsql(\"DROP table IF EXISTS sale\")", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 3345.56494140625, "end_time": 1685563973054.938}}, "collapsed": false}}, {"source": "## Data Setup", "cell_type": "markdown", "metadata": {"editable": true, "deletable": true}}, {"execution_count": null, "cell_type": "code", "source": "val noOfCustomers = 1000000\nval noOfSaleTx = 1000000000\n\n//possible random state\nval possibleCustAddState = List(\"AL\",\"AK\",\"AZ\",\"AR\",\"AS\",\"CA\",\"CO\",\"CT\",\n                                    \"DE\",\"DC\",\"FL\",\"GA\",\"GU\",\"HI\",\"ID\",\"IL\",\"IN\",\"IA\",\"KS\",\"KY\")\nval stateRandom=scala.util.Random.nextInt(possibleCustAddState.length)\n\n//UDF to generate random string with given length\nval randomString =udf((length: Int)=> scala.util.Random.alphanumeric.take(length).mkString)\nspark.udf.register(\"randomString\",randomString)\n//UDF to generate random float\nval randomFloat=udf(()=>scala.util.Random.nextFloat())\nspark.udf.register(\"randomFloat\",randomFloat)\n//UDF to get random state\nval randomAddState=udf(()=>possibleCustAddState(scala.util.Random.nextInt(possibleCustAddState.length)))\nspark.udf.register(\"randomAddState\",randomAddState)\n\n\n/* list of customer schema \nroot\n |-- name: string (nullable = true)\n |-- address_state: float (nullable = true)\n |-- customer_id: long (nullable = false)\n*/\nval customerDF = sql(s\"\"\"SELECT randomString(10) as name,\n                        randomAddState() as address_state,\n                        id as customer_id FROM range($noOfCustomers)\"\"\")\n\ncustomerDF.write.format(\"parquet\").mode(\"overwrite\").saveAsTable(\"customer\")\n\n/* list of sales transactions \n root\n |-- customer_id: integer (nullable = true)\n |-- tx_value: integer (nullable = false)\n |-- tx_id: long (nullable = false)\n |-- tx_date: date (nullable = true)\n*/\nval salesDF = sql(s\"\"\"SELECT CAST(randomFloat() * $noOfCustomers AS INT) AS customer_id,\n                      round(randomFloat()*100,2) as tx_value,\n                      id as tx_id,\n                      DATE_ADD(current_date(), - CAST(randomFloat() * 90 AS INT)) AS tx_date\n                      FROM range($noOfSaleTx)\"\"\")\n\nsalesDF.write.format(\"parquet\").mode(\"overwrite\").saveAsTable(\"sale\")", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 145936.501953125, "end_time": 1685564132812.329}}, "editable": true, "collapsed": false, "deletable": true}}, {"source": "## Analysis", "cell_type": "markdown", "metadata": {"editable": true, "deletable": true}}, {"execution_count": null, "cell_type": "code", "source": "%%sql\nSELECT count(*), address_state FROM customer WHERE address_state=\"IL\" GROUP BY address_state", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 2304.135009765625, "end_time": 1685564908189.732}}, "collapsed": false}}, {"source": "## AQE Disable", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "%%sql\nSELECT tx_date, sum(tx_value) AS total_sales\nFROM sale\nJOIN customer ON customer.customer_id = sale.customer_id\nWHERE address_state=\"IL\"\nGROUP BY tx_date", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 142169.11499023438, "end_time": 1685564773939.99}}, "editable": true, "collapsed": false, "deletable": true}}, {"source": "## AQE Enable", "cell_type": "markdown", "metadata": {"cell_status": {"execute_time": {"duration": 245.739013671875, "end_time": 1685566591867.472}}}}, {"execution_count": null, "cell_type": "code", "source": "// Enable AQE\nsql(\"SET spark.sql.adaptive.enabled=true\")\nsql(\"set spark.sql.adaptive.localShuffleReader.enabled=true\")", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 751.22607421875, "end_time": 1685565120102.899}}, "collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "%%sql\nSELECT tx_date, sum(tx_value) AS total_sales\nFROM sale\nJOIN customer ON customer.customer_id = sale.customer_id\nWHERE address_state=\"IL\"\nGROUP BY tx_date", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 111820.2021484375, "end_time": 1685565243574.489}}, "collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "", "outputs": [], "metadata": {"collapsed": true}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "Spark", "name": "sparkkernel", "language": ""}, "language_info": {"mimetype": "text/x-scala", "pygments_lexer": "scala", "name": "scala", "codemirror_mode": "text/x-scala"}}}